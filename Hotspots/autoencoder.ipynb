{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.backend.tensorflow_backend.set_session(session)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HEADER ##\n",
    "# description: use autoencoder to reduce dimensionality of sequence embeddings\n",
    "# author: HR\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.system('pwd')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend.tensorflow_backend as K\n",
    "K.set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUT ###\n",
    "\n",
    "# seq2vec + TF-IDF\n",
    "seq2vec = pd.read_csv('../RUNS/HumanProteome/word2vec_model/hp_sequence_repres_w5_d100_seq2vec-TFIDF.csv')\n",
    "\n",
    "meta = seq2vec.iloc[:, 0:3]\n",
    "emb = np.array(seq2vec.iloc[:, 3:103], dtype = 'float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "encoded (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "decoded (Dense)              (None, 100)               3300      \n",
      "=================================================================\n",
      "Total params: 6,532\n",
      "Trainable params: 6,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### MAIN PART ###\n",
    "\n",
    "# model\n",
    "\n",
    "def build_and_compile_AE():\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    inp = layers.Input(shape = (100, ), name = 'input')\n",
    "    encoded = layers.Dense(32, activation = 'tanh', name = 'encoded')(inp)\n",
    "    decoded = layers.Dense(100, activation = 'sigmoid', name = 'decoded')(encoded)\n",
    "    \n",
    "    autoencoder = keras.Model(inputs = inp, outputs = decoded)\n",
    "    \n",
    "    autoencoder.compile(optimizer = keras.optimizers.Adadelta(),\n",
    "                       loss = keras.losses.BinaryCrossentropy(),\n",
    "                       metrics = ['accuracy'])\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "AE = build_and_compile_AE()\n",
    "AE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33888, 100)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data\n",
    "X_train, X_test = train_test_split(emb, test_size = .2)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33888 samples, validate on 8473 samples\n",
      "Epoch 1/100\n",
      "33888/33888 [==============================] - 1s 29us/sample - loss: -0.6671 - acc: 0.7723 - val_loss: -1.2076 - val_acc: 0.9000\n",
      "Epoch 2/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.2468 - acc: 0.8444 - val_loss: -1.3061 - val_acc: 0.8446\n",
      "Epoch 3/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.3420 - acc: 0.8700 - val_loss: -1.4226 - val_acc: 0.8849\n",
      "Epoch 4/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.4460 - acc: 0.8934 - val_loss: -1.4924 - val_acc: 0.8946\n",
      "Epoch 5/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.4872 - acc: 0.8998 - val_loss: -1.5126 - val_acc: 0.8984\n",
      "Epoch 6/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.4979 - acc: 0.9009 - val_loss: -1.5186 - val_acc: 0.8989\n",
      "Epoch 7/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5031 - acc: 0.9017 - val_loss: -1.5223 - val_acc: 0.8994\n",
      "Epoch 8/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5063 - acc: 0.9019 - val_loss: -1.5249 - val_acc: 0.9000\n",
      "Epoch 9/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5085 - acc: 0.9021 - val_loss: -1.5268 - val_acc: 0.9000\n",
      "Epoch 10/100\n",
      "33888/33888 [==============================] - 1s 23us/sample - loss: -1.5106 - acc: 0.9023 - val_loss: -1.5285 - val_acc: 0.9000\n",
      "Epoch 11/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5123 - acc: 0.9025 - val_loss: -1.5300 - val_acc: 0.9000\n",
      "Epoch 12/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5138 - acc: 0.9025 - val_loss: -1.5315 - val_acc: 0.9000\n",
      "Epoch 13/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5154 - acc: 0.9025 - val_loss: -1.5329 - val_acc: 0.9000\n",
      "Epoch 14/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5168 - acc: 0.9025 - val_loss: -1.5343 - val_acc: 0.9000\n",
      "Epoch 15/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5182 - acc: 0.9025 - val_loss: -1.5354 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5192 - acc: 0.9022 - val_loss: -1.5364 - val_acc: 0.8992\n",
      "Epoch 17/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5202 - acc: 0.9016 - val_loss: -1.5372 - val_acc: 0.8991\n",
      "Epoch 18/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5210 - acc: 0.9011 - val_loss: -1.5379 - val_acc: 0.8983\n",
      "Epoch 19/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5217 - acc: 0.9003 - val_loss: -1.5386 - val_acc: 0.8974\n",
      "Epoch 20/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5223 - acc: 0.8998 - val_loss: -1.5391 - val_acc: 0.8970\n",
      "Epoch 21/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5229 - acc: 0.8993 - val_loss: -1.5396 - val_acc: 0.8964\n",
      "Epoch 22/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5233 - acc: 0.8988 - val_loss: -1.5400 - val_acc: 0.8945\n",
      "Epoch 23/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5237 - acc: 0.8983 - val_loss: -1.5403 - val_acc: 0.8945\n",
      "Epoch 24/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5240 - acc: 0.8970 - val_loss: -1.5407 - val_acc: 0.8931\n",
      "Epoch 25/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5244 - acc: 0.8960 - val_loss: -1.5410 - val_acc: 0.8912\n",
      "Epoch 26/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5248 - acc: 0.8950 - val_loss: -1.5413 - val_acc: 0.8901\n",
      "Epoch 27/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5250 - acc: 0.8934 - val_loss: -1.5415 - val_acc: 0.8889\n",
      "Epoch 28/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5254 - acc: 0.8918 - val_loss: -1.5418 - val_acc: 0.8858\n",
      "Epoch 29/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5256 - acc: 0.8898 - val_loss: -1.5420 - val_acc: 0.8873\n",
      "Epoch 30/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5259 - acc: 0.8890 - val_loss: -1.5423 - val_acc: 0.8862\n",
      "Epoch 31/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5262 - acc: 0.8882 - val_loss: -1.5425 - val_acc: 0.8856\n",
      "Epoch 32/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5264 - acc: 0.8867 - val_loss: -1.5427 - val_acc: 0.8823\n",
      "Epoch 33/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5267 - acc: 0.8856 - val_loss: -1.5430 - val_acc: 0.8829\n",
      "Epoch 34/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5269 - acc: 0.8844 - val_loss: -1.5432 - val_acc: 0.8833\n",
      "Epoch 35/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5271 - acc: 0.8834 - val_loss: -1.5434 - val_acc: 0.8796\n",
      "Epoch 36/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5273 - acc: 0.8829 - val_loss: -1.5436 - val_acc: 0.8826\n",
      "Epoch 37/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5276 - acc: 0.8820 - val_loss: -1.5438 - val_acc: 0.8791\n",
      "Epoch 38/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5278 - acc: 0.8811 - val_loss: -1.5439 - val_acc: 0.8809\n",
      "Epoch 39/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5280 - acc: 0.8805 - val_loss: -1.5441 - val_acc: 0.8769\n",
      "Epoch 40/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5282 - acc: 0.8796 - val_loss: -1.5443 - val_acc: 0.8789\n",
      "Epoch 41/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5284 - acc: 0.8785 - val_loss: -1.5445 - val_acc: 0.8782\n",
      "Epoch 42/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5286 - acc: 0.8783 - val_loss: -1.5447 - val_acc: 0.8758\n",
      "Epoch 43/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5289 - acc: 0.8780 - val_loss: -1.5448 - val_acc: 0.8791\n",
      "Epoch 44/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5290 - acc: 0.8773 - val_loss: -1.5450 - val_acc: 0.8757\n",
      "Epoch 45/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5293 - acc: 0.8770 - val_loss: -1.5452 - val_acc: 0.8761\n",
      "Epoch 46/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5294 - acc: 0.8758 - val_loss: -1.5453 - val_acc: 0.8740\n",
      "Epoch 47/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5296 - acc: 0.8754 - val_loss: -1.5455 - val_acc: 0.8728\n",
      "Epoch 48/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5298 - acc: 0.8739 - val_loss: -1.5457 - val_acc: 0.8734\n",
      "Epoch 49/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5300 - acc: 0.8746 - val_loss: -1.5458 - val_acc: 0.8729\n",
      "Epoch 50/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5302 - acc: 0.8749 - val_loss: -1.5459 - val_acc: 0.8750\n",
      "Epoch 51/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5303 - acc: 0.8743 - val_loss: -1.5461 - val_acc: 0.8731\n",
      "Epoch 52/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5306 - acc: 0.8746 - val_loss: -1.5462 - val_acc: 0.8754\n",
      "Epoch 53/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5308 - acc: 0.8746 - val_loss: -1.5463 - val_acc: 0.8721\n",
      "Epoch 54/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5308 - acc: 0.8728 - val_loss: -1.5464 - val_acc: 0.8718\n",
      "Epoch 55/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5309 - acc: 0.8718 - val_loss: -1.5465 - val_acc: 0.8719\n",
      "Epoch 56/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5311 - acc: 0.8720 - val_loss: -1.5466 - val_acc: 0.8688\n",
      "Epoch 57/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5312 - acc: 0.8708 - val_loss: -1.5467 - val_acc: 0.8719\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5314 - acc: 0.8705 - val_loss: -1.5468 - val_acc: 0.8722\n",
      "Epoch 59/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5314 - acc: 0.8702 - val_loss: -1.5468 - val_acc: 0.8691\n",
      "Epoch 60/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5315 - acc: 0.8691 - val_loss: -1.5469 - val_acc: 0.8691\n",
      "Epoch 61/100\n",
      "33888/33888 [==============================] - 1s 23us/sample - loss: -1.5316 - acc: 0.8691 - val_loss: -1.5470 - val_acc: 0.8685\n",
      "Epoch 62/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5317 - acc: 0.8679 - val_loss: -1.5470 - val_acc: 0.8682\n",
      "Epoch 63/100\n",
      "33888/33888 [==============================] - 1s 23us/sample - loss: -1.5318 - acc: 0.8680 - val_loss: -1.5471 - val_acc: 0.8691\n",
      "Epoch 64/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5319 - acc: 0.8687 - val_loss: -1.5471 - val_acc: 0.8683\n",
      "Epoch 65/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5321 - acc: 0.8690 - val_loss: -1.5472 - val_acc: 0.8691\n",
      "Epoch 66/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5322 - acc: 0.8692 - val_loss: -1.5473 - val_acc: 0.8691\n",
      "Epoch 67/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5323 - acc: 0.8688 - val_loss: -1.5473 - val_acc: 0.8676\n",
      "Epoch 68/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5323 - acc: 0.8685 - val_loss: -1.5474 - val_acc: 0.8722\n",
      "Epoch 69/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5324 - acc: 0.8694 - val_loss: -1.5475 - val_acc: 0.8691\n",
      "Epoch 70/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5325 - acc: 0.8691 - val_loss: -1.5475 - val_acc: 0.8663\n",
      "Epoch 71/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5326 - acc: 0.8687 - val_loss: -1.5476 - val_acc: 0.8697\n",
      "Epoch 72/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5327 - acc: 0.8697 - val_loss: -1.5477 - val_acc: 0.8679\n",
      "Epoch 73/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5328 - acc: 0.8696 - val_loss: -1.5477 - val_acc: 0.8691\n",
      "Epoch 74/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5329 - acc: 0.8699 - val_loss: -1.5478 - val_acc: 0.8704\n",
      "Epoch 75/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5330 - acc: 0.8715 - val_loss: -1.5479 - val_acc: 0.8714\n",
      "Epoch 76/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5331 - acc: 0.8744 - val_loss: -1.5480 - val_acc: 0.8717\n",
      "Epoch 77/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5332 - acc: 0.8757 - val_loss: -1.5481 - val_acc: 0.8791\n",
      "Epoch 78/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5334 - acc: 0.8842 - val_loss: -1.5482 - val_acc: 0.8845\n",
      "Epoch 79/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5336 - acc: 0.8890 - val_loss: -1.5484 - val_acc: 0.8900\n",
      "Epoch 80/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5337 - acc: 0.8918 - val_loss: -1.5485 - val_acc: 0.8875\n",
      "Epoch 81/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5340 - acc: 0.8915 - val_loss: -1.5487 - val_acc: 0.8893\n",
      "Epoch 82/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5341 - acc: 0.8901 - val_loss: -1.5488 - val_acc: 0.8866\n",
      "Epoch 83/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5343 - acc: 0.8889 - val_loss: -1.5489 - val_acc: 0.8885\n",
      "Epoch 84/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5345 - acc: 0.8873 - val_loss: -1.5491 - val_acc: 0.8835\n",
      "Epoch 85/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5347 - acc: 0.8866 - val_loss: -1.5492 - val_acc: 0.8826\n",
      "Epoch 86/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5348 - acc: 0.8856 - val_loss: -1.5493 - val_acc: 0.8848\n",
      "Epoch 87/100\n",
      "33888/33888 [==============================] - 1s 23us/sample - loss: -1.5349 - acc: 0.8847 - val_loss: -1.5494 - val_acc: 0.8826\n",
      "Epoch 88/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5352 - acc: 0.8836 - val_loss: -1.5495 - val_acc: 0.8807\n",
      "Epoch 89/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5353 - acc: 0.8826 - val_loss: -1.5497 - val_acc: 0.8823\n",
      "Epoch 90/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5354 - acc: 0.8816 - val_loss: -1.5498 - val_acc: 0.8776\n",
      "Epoch 91/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5356 - acc: 0.8800 - val_loss: -1.5499 - val_acc: 0.8755\n",
      "Epoch 92/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5357 - acc: 0.8788 - val_loss: -1.5500 - val_acc: 0.8756\n",
      "Epoch 93/100\n",
      "33888/33888 [==============================] - 1s 26us/sample - loss: -1.5358 - acc: 0.8784 - val_loss: -1.5501 - val_acc: 0.8745\n",
      "Epoch 94/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5360 - acc: 0.8774 - val_loss: -1.5502 - val_acc: 0.8761\n",
      "Epoch 95/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5361 - acc: 0.8767 - val_loss: -1.5503 - val_acc: 0.8730\n",
      "Epoch 96/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5362 - acc: 0.8754 - val_loss: -1.5504 - val_acc: 0.8735\n",
      "Epoch 97/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5364 - acc: 0.8748 - val_loss: -1.5505 - val_acc: 0.8728\n",
      "Epoch 98/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5365 - acc: 0.8741 - val_loss: -1.5506 - val_acc: 0.8716\n",
      "Epoch 99/100\n",
      "33888/33888 [==============================] - 1s 24us/sample - loss: -1.5367 - acc: 0.8731 - val_loss: -1.5507 - val_acc: 0.8716\n",
      "Epoch 100/100\n",
      "33888/33888 [==============================] - 1s 25us/sample - loss: -1.5368 - acc: 0.8723 - val_loss: -1.5508 - val_acc: 0.8702\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ef8430a75fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             validation_data = (X_test, X_test))\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1113\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m       \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples_or_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_end\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mmake_batches\u001b[0;34m(size, batch_size)\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0mof\u001b[0m \u001b[0marray\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m   \"\"\"\n\u001b[0;32m--> 488\u001b[0;31m   \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m   return [(i * batch_size, min(size, (i + 1) * batch_size))\n\u001b[1;32m    490\u001b[0m           for i in range(0, num_batches)]\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "\n",
    "fit = AE.fit(X_train, X_train,\n",
    "            epochs = 100,\n",
    "            batch_size = 64,\n",
    "            shuffle = True,\n",
    "            verbose = 1,\n",
    "            validation_data = (X_test, X_test))\n",
    "\n",
    "AE.predict(X_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and metrics\n",
    "AE.save_weights('AE/seq2vec-TFIDF.h5')\n",
    "\n",
    "val = []\n",
    "name = list(fit.history.keys())\n",
    "for i, elem in enumerate(fit.history.keys()):\n",
    "    val.append(fit.history[elem])\n",
    "\n",
    "m = list(zip(name, val))\n",
    "m = pd.DataFrame(m)\n",
    "pd.DataFrame.to_csv(m, 'AE/metrics_ext_seq2vec-TFIDF.csv', header=False, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
